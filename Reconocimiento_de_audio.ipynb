{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOewXO6Jg9NVluITBYrrC1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismaelllamur013/HR2-BotTelegramAudio/blob/main/Reconocimiento_de_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descripcion rapida:**\n",
        "\n",
        "Esto es un pequeño notebook en donde buscamos entrenar de forma muy precaria y rapidamente un modelo de deteccion de audio usando una maquina de soportes vectoriales. Basicamente lo que buscamos obtener al final es un modelo para ser usado en la aplicacion que queramos.\n",
        "\n",
        "A priori lo que se hizo es que a partir de un video, se extraiga su audio.\n",
        "\n",
        "Para su uso en el modelo remuestreamos a una frecuencia de 44100 Hz, el doble del oido humano, esto para definir una misma frecuencia para todos los audios utilizados para entrenar al modelo.\n",
        "\n",
        "Posteriormente se busco que todos los audios trabajen con un mismo tamaño, esto para que al modelo esten entrando datos de igual dimenciones\n",
        "\n",
        "Para modelos de audio agregamos ruido blanco en algunos casos para evaluar que tan bien puede seguir prediciendo nuestro modelo segun cambiamos la relacion señal ruido\n",
        "\n",
        "Con todo el preprocesamiento definido entrenamos el modelo, evaluaciamos y si es de utilidad, reentrenamos con todos los datos y obtenemos nuestro modelo para usar"
      ],
      "metadata": {
        "id": "xf-MaXOqNBlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extaer audio del video\n"
      ],
      "metadata": {
        "id": "8XKtfe5aQkZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install moviepy"
      ],
      "metadata": {
        "id": "dmJADHDYNvGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552c78e8-60b6-4db2-eae2-bcd747097953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def extraer_audio(input_video, output_audio):\n",
        "    # Cargar el archivo de video\n",
        "    video_clip = VideoFileClip(input_video)\n",
        "\n",
        "    # Extraer el audio del video\n",
        "    audio_clip = video_clip.audio\n",
        "\n",
        "    # Guardar el audio en un archivo separado\n",
        "    audio_clip.write_audiofile(output_audio)\n",
        "\n",
        "    # Cerrar los clips para liberar recursos\n",
        "    audio_clip.close()\n",
        "    video_clip.close()"
      ],
      "metadata": {
        "id": "tCvDHjC_Npbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso\n",
        "input_video = \"NoSoda12.mp4\"\n",
        "output_audio = \"audio_extraido16.wav\"\n",
        "extraer_audio(input_video, output_audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZdF8-2FPfwN",
        "outputId": "49e3819f-a06b-4e50-f568-9a1cfe3ddac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in audio_extraido16.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remuestreo de las señales de audio"
      ],
      "metadata": {
        "id": "TRiv4qWzQpTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWfkNOJoQurO",
        "outputId": "ce82b4ee-aec6-48a2-e0f2-0d788c874252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def remuestrear_audio(input_audio, output_audio, nueva_frecuencia):\n",
        "    # Cargar el archivo de audio\n",
        "    audio = AudioSegment.from_file(input_audio)\n",
        "\n",
        "    # Realizar el re-muestreo a la nueva frecuencia\n",
        "    audio_remuestreado = audio.set_frame_rate(nueva_frecuencia)\n",
        "\n",
        "    # Guardar el audio re-muestreado en un nuevo archivo\n",
        "    audio_remuestreado.export(output_audio, format=\"wav\")\n"
      ],
      "metadata": {
        "id": "FuSlTtHDQyIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso\n",
        "input_audio = \"audio_extraido16.wav\"\n",
        "output_audio_remuestreado = \"audio_remuestreado16.wav\"\n",
        "nueva_frecuencia = 44100  # Puedes ajustar la frecuencia según tus necesidades\n",
        "\n",
        "remuestrear_audio(input_audio, output_audio_remuestreado, nueva_frecuencia)"
      ],
      "metadata": {
        "id": "LumDffYuQ0j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos con el mismo tamaño"
      ],
      "metadata": {
        "id": "VWQhFlJTbVj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9sveW7BbZpS",
        "outputId": "5fa53d48-c43b-493a-e834-0fcdb6fc2a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "\n",
        "def ajustar_longitud_audio(audio_path, longitud_deseada):\n",
        "    # Cargar el archivo de audio\n",
        "    audio, sample_rate = librosa.load(audio_path, sr=None)\n",
        "\n",
        "    # Ajustar la longitud del audio\n",
        "    if len(audio) > longitud_deseada:\n",
        "        audio_ajustado = audio[:longitud_deseada]\n",
        "    elif len(audio) < longitud_deseada:\n",
        "        padding = longitud_deseada - len(audio)\n",
        "        audio_ajustado = np.pad(audio, (0, padding), mode='constant')\n",
        "    else:\n",
        "        audio_ajustado = audio\n",
        "\n",
        "    return audio_ajustado, sample_rate"
      ],
      "metadata": {
        "id": "P8YfwTjabYPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Longitud deseada para todos los archivos de audio (ajusta según tus necesidades)\n",
        "longitud_deseada = 44100*30 # Ejemplo: 1 segundo a 44.1 kHz\n",
        "\n",
        "# Ruta del archivo de entrada y salida (ajusta según tus necesidades)\n",
        "audio_input_path = \"audio_remuestreado16.wav\"\n",
        "audio_output_path = \"audio_fin16.wav\"\n",
        "\n",
        "# Cargar y ajustar la longitud del audio\n",
        "audio_ajustado, sample_rate = ajustar_longitud_audio(audio_input_path, longitud_deseada)\n",
        "\n",
        "# Exportar el audio ajustado a un nuevo archivo WAV\n",
        "wavfile.write(audio_output_path, sample_rate, audio_ajustado)"
      ],
      "metadata": {
        "id": "z4BdNCGzbi4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generador de ruido en los audios\n"
      ],
      "metadata": {
        "id": "FalyIefMOhMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "# Cargar el archivo de audio original\n",
        "audio_path = \"audio_fin4.wav\"\n",
        "y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "# Generar ruido blanco del mismo tamaño que el audio original\n",
        "noise = np.random.normal(0, 0.005, len(y))  # Puedes ajustar la amplitud del ruido según tus necesidades\n",
        "\n",
        "# Mezclar el audio original con el ruido\n",
        "mixed_audio = y + noise*20\n",
        "\n",
        "# Guardar el audio mezclado en un nuevo archivo WAV\n",
        "output_path = \"audio_fin4_2.wav\"\n",
        "sf.write(output_path, mixed_audio, sr)\n"
      ],
      "metadata": {
        "id": "IE6kgLThb1QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predecir"
      ],
      "metadata": {
        "id": "e-i20qnhUEbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSJIxZ-OUDWT",
        "outputId": "674fca98-9959-4646-873c-f4b1b4efbf91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from scipy.io import wavfile  # Para leer archivos de audio WAV"
      ],
      "metadata": {
        "id": "U_g_UgRjZlMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extraer_caracteristicas(audio_path):\n",
        "    # Implementa aquí la extracción de características del audio\n",
        "    # Puedes utilizar bibliotecas como librosa para extraer características\n",
        "    # Aquí, se utiliza un ejemplo simple, considerando la longitud del audio\n",
        "    _, audio_data = wavfile.read(audio_path)\n",
        "    #longitud_audio = len(audio_data)\n",
        "    #return np.array([longitud_audio])\n",
        "    return audio_data"
      ],
      "metadata": {
        "id": "tZ7cueT7UIbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar datos de ejemplo (reemplaza esto con tus propios datos)\n",
        "audio_paths_tipo1 = [\"audio_fin1.wav\", \"audio_fin2.wav\", \"audio_fin3.wav\", \"audio_fin4.wav\",\"audio_fin1_1.wav\", \"audio_fin2_1.wav\", \"audio_fin3_1.wav\", \"audio_fin4_1.wav\",\"audio_fin1_2.wav\", \"audio_fin2_2.wav\", \"audio_fin3_2.wav\", \"audio_fin4_2.wav\"]\n",
        "audio_paths_tipo2 = [\"audio_fin5.wav\", \"audio_fin6.wav\", \"audio_fin7.wav\", \"audio_fin8.wav\",\"audio_fin9.wav\", \"audio_fin10.wav\", \"audio_fin11.wav\", \"audio_fin12.wav\",\"audio_fin13.wav\", \"audio_fin14.wav\", \"audio_fin15.wav\", \"audio_fin16.wav\"]\n",
        "\n",
        "X_tipo1 = np.array([extraer_caracteristicas(path) for path in audio_paths_tipo1])\n",
        "X_tipo2 = np.array([extraer_caracteristicas(path) for path in audio_paths_tipo2])"
      ],
      "metadata": {
        "id": "t-quv48IUTVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etiquetas de clases\n",
        "y_tipo1 = np.ones(len(X_tipo1))  # Tipo 1\n",
        "y_tipo2 = np.zeros(len(X_tipo2))  # Tipo 2"
      ],
      "metadata": {
        "id": "a2oxHwIfUYWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenar datos y etiquetas\n",
        "X = np.concatenate([X_tipo1, X_tipo2])\n",
        "y = np.concatenate([y_tipo1, y_tipo2])"
      ],
      "metadata": {
        "id": "2SAKBT5SUcPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
      ],
      "metadata": {
        "id": "1SKPrT93UeO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y entrenar el clasificador SVM\n",
        "classifier = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1))\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "c0U_b3CbUjXG",
        "outputId": "e51bd142-95ef-4c62-c082-1fb2f3a68cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc', SVC(C=1, kernel='linear'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;, SVC(C=1, kernel=&#x27;linear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;, SVC(C=1, kernel=&#x27;linear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluar la precisión del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Precisión del modelo: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "523zoO6aUltx",
        "outputId": "4b2b72ba-37d9-4d39-d8ca-ee5d9d0070f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y entrenar un modelo SVM de clasificación\n",
        "modelo_svm = SVC(kernel='linear')\n",
        "modelo_svm.fit(X, y)\n",
        "\n",
        "# Obtener los parámetros del modelo\n",
        "coeficientes = modelo_svm.coef_\n",
        "intercepto = modelo_svm.intercept_\n",
        "\n",
        "# Imprimir los parámetros\n",
        "print(\"Coeficientes:\", coeficientes)\n",
        "print(\"Intercepto:\", intercepto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh9_zOcGGIhL",
        "outputId": "1e6fb1ce-2ea7-4a3b-e53d-2d48d4e6209c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes: [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.04205524e-05\n",
            "  2.07134433e-05 1.97532943e-05]]\n",
            "Intercepto: [-0.43110799]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# ... (Código anterior para obtener coeficientes e intercepto)\n",
        "\n",
        "# Nuevos datos de entrada para hacer predicciones\n",
        "nuevos_datos = X_test[0]\n",
        "\n",
        "# Calcular el valor de decisión sin utilizar el objeto modelo\n",
        "decision_values = np.dot(coeficientes, nuevos_datos.T) - intercepto\n",
        "\n",
        "# Aplicar la función de signo para obtener las predicciones (1 para clase positiva, -1 para clase negativa)\n",
        "predicciones = np.sign(decision_values)\n",
        "\n",
        "# Imprimir las predicciones\n",
        "print(\"Predicciones:\", predicciones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmEVmkdlHBj3",
        "outputId": "aedd09f3-43a1-4d2a-9bb8-c0a74c27ccf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones: [-1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo de texto\n",
        "ruta_archivo = \"coeficientes.txt\"\n",
        "np.savetxt(ruta_archivo, coeficientes)\n",
        "# Ruta del archivo de texto\n",
        "ruta_archivo = \"intercepto.txt\"\n",
        "np.savetxt(ruta_archivo, intercepto)\n"
      ],
      "metadata": {
        "id": "Cn9rC6_VH85R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coeficientes:\", coeficientes)\n",
        "print(\"Intercepto:\", intercepto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI6dE8n-gJVU",
        "outputId": "a6f429b9-2bed-4561-8669-f0ab5221c5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes: [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.04205524e-05\n",
            "  2.07134433e-05 1.97532943e-05]]\n",
            "Intercepto: [-0.43110799]\n"
          ]
        }
      ]
    }
  ]
}